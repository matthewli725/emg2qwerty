{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive\n",
        "\n",
        "Remember to use GPU runtime before mounting your Google Drive. (Runtime --> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCSU4HrvkVDq"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n",
        "Replace `Your_Dir` with your own path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-gfQ17SmkfOK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty\n"
          ]
        }
      ],
      "source": [
        "cd emg2qwerty/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFFKvhs4tAp5"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
          ]
        }
      ],
      "source": [
        "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n84M6KLmkp2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2026-02-19 12:57:41,795][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2026-02-19 12:57:41,798][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2026-02-19 12:57:41,890][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/logs/2026-02-19/12-57-41/lightning_logs\n",
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2687: UserWarning: The operator 'aten::_ctc_loss' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
            "  return torch.ctc_loss(\n",
            "Epoch 0:  94%|████████████▎| 120/127 [05:04<00:17,  2.54s/it, loss=122, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|████████████▍| 121/127 [05:22<00:15,  2.67s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▍| 122/127 [05:24<00:13,  2.66s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▌| 123/127 [05:25<00:10,  2.65s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▋| 124/127 [05:26<00:07,  2.63s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▊| 125/127 [05:27<00:05,  2.62s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▉| 126/127 [05:28<00:02,  2.60s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 127/127 [05:29<00:00,  2.59s/it, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 127/127 [05:29<00:00,  2.59s/it, loss=122, v_num=0]\u001b[AEpoch 0, global step 120: 'val/CER' reached 1358.08594 (best 1358.08594), saving model to '/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/logs/2026-02-19/12-57-41/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94%|███████████▎| 120/127 [05:03<00:17,  2.53s/it, loss=3.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 121/127 [05:14<00:15,  2.60s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 122/127 [05:16<00:12,  2.60s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▌| 123/127 [05:18<00:10,  2.59s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▋| 124/127 [05:19<00:07,  2.57s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▊| 125/127 [05:20<00:05,  2.56s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▉| 126/127 [05:21<00:02,  2.55s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 127/127 [05:21<00:00,  2.53s/it, loss=3.43, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 127/127 [05:21<00:00,  2.53s/it, loss=3.43, v_num=0]\u001b[AEpoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/Users/matthewli/Desktop/2026-winter/ecec147a/final_project/emg2qwerty/logs/2026-02-19/12-57-41/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94%|███████████▎| 120/127 [14:43<00:51,  7.36s/it, loss=3.25, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  95%|███████████▍| 121/127 [15:00<00:44,  7.44s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2:  96%|███████████▌| 122/127 [15:04<00:37,  7.41s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2:  97%|███████████▌| 123/127 [15:05<00:29,  7.36s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2:  98%|███████████▋| 124/127 [15:05<00:21,  7.30s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2:  98%|███████████▊| 125/127 [15:06<00:14,  7.25s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2:  99%|███████████▉| 126/127 [15:07<00:07,  7.20s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2: 100%|████████████| 127/127 [15:07<00:00,  7.15s/it, loss=3.25, v_num=0]\u001b[A\n",
            "Epoch 2: 100%|████████████| 127/127 [15:07<00:00,  7.15s/it, loss=3.25, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94%|███████████▎| 120/127 [05:15<00:18,  2.63s/it, loss=3.21, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  95%|███████████▍| 121/127 [05:32<00:16,  2.75s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3:  96%|███████████▌| 122/127 [05:37<00:13,  2.77s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3:  97%|███████████▌| 123/127 [05:38<00:11,  2.75s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3:  98%|███████████▋| 124/127 [05:39<00:08,  2.74s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3:  98%|███████████▊| 125/127 [05:40<00:05,  2.72s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3:  99%|███████████▉| 126/127 [05:41<00:02,  2.71s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3: 100%|████████████| 127/127 [05:41<00:00,  2.69s/it, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 3: 100%|████████████| 127/127 [05:41<00:00,  2.69s/it, loss=3.21, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94%|███████████▎| 120/127 [05:36<00:19,  2.81s/it, loss=3.19, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  95%|███████████▍| 121/127 [05:52<00:17,  2.92s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4:  96%|███████████▌| 122/127 [05:56<00:14,  2.92s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4:  97%|███████████▌| 123/127 [05:57<00:11,  2.91s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4:  98%|███████████▋| 124/127 [05:58<00:08,  2.89s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4:  98%|███████████▊| 125/127 [05:59<00:05,  2.88s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4:  99%|███████████▉| 126/127 [06:00<00:02,  2.86s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4: 100%|████████████| 127/127 [06:01<00:00,  2.84s/it, loss=3.19, v_num=0]\u001b[A\n",
            "Epoch 4: 100%|████████████| 127/127 [06:01<00:00,  2.84s/it, loss=3.19, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94%|███████████▎| 120/127 [05:13<00:18,  2.61s/it, loss=3.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  95%|███████████▍| 121/127 [05:32<00:16,  2.74s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5:  96%|███████████▌| 122/127 [05:34<00:13,  2.74s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5:  97%|███████████▌| 123/127 [05:35<00:10,  2.73s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5:  98%|███████████▋| 124/127 [05:36<00:08,  2.71s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5:  98%|███████████▊| 125/127 [05:37<00:05,  2.70s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5:  99%|███████████▉| 126/127 [05:37<00:02,  2.68s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5: 100%|████████████| 127/127 [05:38<00:00,  2.66s/it, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 5: 100%|████████████| 127/127 [05:38<00:00,  2.66s/it, loss=3.04, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94%|███████████▎| 120/127 [21:25<01:14, 10.71s/it, loss=3.01, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  95%|███████████▍| 121/127 [21:39<01:04, 10.74s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6:  96%|███████████▌| 122/127 [21:59<00:54, 10.82s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6:  97%|███████████▌| 123/127 [22:04<00:43, 10.77s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6:  98%|███████████▋| 124/127 [22:05<00:32, 10.69s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6:  98%|███████████▊| 125/127 [22:06<00:21, 10.61s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6:  99%|███████████▉| 126/127 [22:07<00:10, 10.54s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6: 100%|████████████| 127/127 [22:08<00:00, 10.46s/it, loss=3.01, v_num=0]\u001b[A\n",
            "Epoch 6: 100%|████████████| 127/127 [22:08<00:00, 10.46s/it, loss=3.01, v_num=0]\u001b[AEpoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  12%|█▌           | 15/127 [00:45<05:39,  3.03s/it, loss=2.99, v_num=0]^C\n",
            "Process Process-6:\n",
            "Process Process-7:\n",
            "Process Process-3:\n",
            "Process Process-1:\n",
            "Process Process-4:\n",
            "Process Process-2:\n",
            "Process Process-8:\n",
            "Process Process-5:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- Replace `Your_Path_to_Checkpoint` with your checkpoint path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p68aDt-8pmGj"
      },
      "outputs": [],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"Your_Path_to_Checkpoint\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \\\n",
        "  # --multirun"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "emg2qwerty",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
